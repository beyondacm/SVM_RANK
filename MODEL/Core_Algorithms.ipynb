{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coefficients( File ) :\n",
    "    with open(File, 'r') as model :\n",
    "        for line in model :\n",
    "            performance = line.split(',')[0]\n",
    "            coefficients = line.split(',')[1:]\n",
    "    coefficients = [float(i) for i in coefficients]\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_coefficients_01 = get_coefficients( '../../Model_Building/MODEL/MODEL_02.txt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( model_coefficients_01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# type(w) : numpy.ndarray\n",
    "# w.shape : 114 x 1\n",
    "\n",
    "def score(coefficients, answer0, answer1):\n",
    "    sub = answer0 - answer1\n",
    "    score = sub.dot(coefficients)\n",
    "    if score >= 0:\n",
    "        return 1\n",
    "    else :\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "# type( coefficients )\n",
    "# answer_i = array( test0.iloc[[0]].values.tolist()[0] )\n",
    "# answer_j = array( test0.iloc[[1]].values.tolist()[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test0\n",
    "# answer_i.shape\n",
    "import operator\n",
    "import collections, math\n",
    "\n",
    "def Rank_List( AnswerList, coefficients ):\n",
    "    Score_Map = collections.defaultdict(lambda : 0)\n",
    "    for i in range( len(AnswerList) - 1 ):\n",
    "\n",
    "        for j in range(i+1, len(AnswerList) ):\n",
    "\n",
    "            #print (i, j)\n",
    "\n",
    "            answer_i = array( AnswerList.iloc[[i]].values.tolist()[0] )\n",
    "            answer_j = array( AnswerList.iloc[[j]].values.tolist()[0] )\n",
    "\n",
    "            key_i = 'A_' + str(i) + '_score'\n",
    "            key_j = 'A_' + str(j) + '_score'\n",
    "\n",
    "            value_i = 0\n",
    "            value_j = 0\n",
    "            value_i += score(coefficients, answer_i, answer_j) \n",
    "            value_j -= score(coefficients, answer_i, answer_j)\n",
    "\n",
    "            Score_Map[key_i] += value_i\n",
    "            Score_Map[key_j] += value_j\n",
    "    \n",
    "    return Score_Map\n",
    "    # Sorted_scores = sorted(Score_Map.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    # return Sorted_scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeDict(Dict, filename, sep):\n",
    "    with open(filename, \"w\") as f:\n",
    "#        for key in dict.keys():            \n",
    "#            f.write(str(key) + \":\" + str(dict[key]) + \"\\n\")\n",
    "        for key, value in sorted( Dict.items() ):\n",
    "            f.write( str(key) + sep + str(value) + '\\n' )\n",
    "\n",
    "def writeList(List, filename) :\n",
    "    with open(filename, 'w') as f:\n",
    "        for i in range( len(List) ) :\n",
    "            # print List[i][0]\n",
    "            # print List[i][1]\n",
    "            f.write( str(List[i][0]) + ':' + str(List[i][1]) + '\\n')\n",
    "            \n",
    "def readDict(filename, sep):\n",
    "    with open(filename, \"r\") as f:\n",
    "        dict = {}\n",
    "        for line in f:\n",
    "            values = line.split(sep)\n",
    "            key = values[0]\n",
    "            value = int(values[1])\n",
    "            #value = values[1].split(',')\n",
    "            #dict[values[0]] = {int(x) for x in values[1:len(values)]}\n",
    "            dict[key] = value\n",
    "        return dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "data_path = './SVM_Data/TEST/'\n",
    "file_list = os.listdir(data_path)\n",
    "File_List_Len = len ( file_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(File_List_Len) :\n",
    "    input_file_name = 'test_' + str(i) + '.csv'\n",
    "    # print input_file_name\n",
    "    test_i = pd.read_csv('./MODEL_Data/TEST/' + input_file_name )\n",
    "    test_i = test_i.fillna(0)\n",
    "    \n",
    "    output_file_name = 'test_' + str(i) + '_dict.txt'\n",
    "    \n",
    "    Ai_List = Rank_List(test_i, model_coefficients_01)\n",
    "    # Ai_Sorted = sorted(Ai_List.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    writeDict( Ai_List , './MODEL_Data/RANK/' + output_file_name, ':')\n",
    "    # print Rank_List(test_i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(File_List_Len) :\n",
    "    input_file_name = 'test_' + str(i) + '_dict.txt'\n",
    "    output_file_name = 'test_' + str(i) + '_sorted.txt'\n",
    "    # print input_file_name\n",
    "    Ai_Dict = readDict('./MODEL_Data/RANK/' + input_file_name, ':')\n",
    "    # print type(Ai_Dict)\n",
    "    Ai_Sorted = sorted(Ai_Dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    # print Ai_Sorted\n",
    "    writeList(Ai_Sorted, './MODEL_Data/RANK/' + output_file_name)\n",
    "    # writeDict(Ai_Sorted, './SVM_Data/RANK/' + output_file_name, ':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Get_Sum_Score( key ) :\n",
    "    sum_score = 0.0\n",
    "    for i in range(File_List_Len) :\n",
    "        input_file_name = 'test_' + str(i) + '_dict.txt'\n",
    "        Ai_Dict = readDict('./MODEL_Data/RANK/' + input_file_name, ':')\n",
    "        # print type(Ai_Dict[key])\n",
    "        # print Ai_Dict[key] \n",
    "        # if Ai_Dict[key] is None :\n",
    "            # Ai_Dict[key] = 0\n",
    "        if key in Ai_Dict :\n",
    "            sum_score += Ai_Dict[key]\n",
    "    return sum_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Get_Sum_Score( 'A_0_score' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ave_List = {}\n",
    "for i in range(10) :\n",
    "    \n",
    "    key = 'A_' + str(i) + '_score'\n",
    "    \n",
    "    sum_score = Get_Sum_Score( key )\n",
    "    ave_score = float(sum_score) / File_List_Len\n",
    "    \n",
    "    Ave_List[key] = ave_score\n",
    "    \n",
    "Ave_List = sorted(Ave_List.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A_5_score', 0.52),\n",
       " ('A_1_score', 0.5),\n",
       " ('A_7_score', 0.4),\n",
       " ('A_9_score', 0.2),\n",
       " ('A_2_score', -0.02),\n",
       " ('A_3_score', -0.06),\n",
       " ('A_6_score', -0.16),\n",
       " ('A_8_score', -0.16),\n",
       " ('A_0_score', -0.18),\n",
       " ('A_4_score', -1.04)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ave_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hit_best( filename ):\n",
    "    hit = 0\n",
    "    with open('./MODEL_Data/RANK/' + filename, \"r\") as f:\n",
    "        best_answer = f.readline()\n",
    "        values = best_answer.split(':')\n",
    "        best_id = values[0]\n",
    "        print best_id\n",
    "        if best_id == 'A_0_score' :\n",
    "            hit = 1\n",
    "        else :\n",
    "            hit = 0\n",
    "        return hit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_5_score\n",
      "A_9_score\n",
      "A_0_score\n",
      "A_1_score\n",
      "A_1_score\n",
      "A_4_score\n",
      "A_7_score\n",
      "A_5_score\n",
      "A_2_score\n",
      "A_1_score\n",
      "A_2_score\n",
      "A_2_score\n",
      "A_4_score\n",
      "A_2_score\n",
      "A_1_score\n",
      "A_3_score\n",
      "A_1_score\n",
      "A_5_score\n",
      "A_7_score\n",
      "A_2_score\n",
      "A_5_score\n",
      "A_6_score\n",
      "A_0_score\n",
      "A_0_score\n",
      "A_5_score\n",
      "A_1_score\n",
      "A_1_score\n",
      "A_4_score\n",
      "A_0_score\n",
      "A_0_score\n",
      "A_3_score\n",
      "A_4_score\n",
      "A_0_score\n",
      "A_5_score\n",
      "A_0_score\n",
      "A_3_score\n",
      "A_4_score\n",
      "A_3_score\n",
      "A_4_score\n",
      "A_0_score\n",
      "A_5_score\n",
      "A_1_score\n",
      "A_0_score\n",
      "A_6_score\n",
      "A_2_score\n",
      "A_3_score\n",
      "A_3_score\n",
      "A_3_score\n",
      "A_0_score\n",
      "A_5_score\n"
     ]
    }
   ],
   "source": [
    "model_hit_best = 0\n",
    "for i in range(File_List_Len) :\n",
    "    \n",
    "    input_file_name = 'test_' + str(i) + '_sorted.txt'\n",
    "    model_hit_best += hit_best( input_file_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hit_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
